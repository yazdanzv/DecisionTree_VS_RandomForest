# DecisionTree_VS_RandomForest
<h3>this program is comparing the decision tree and random forest on the following dataset</h3> 
</br>
<h4>results are in the below pictures :</h4>
</br>
</br>
Decision Tree on Test Dataset
<img src="https://github.com/yazdanzv/DecisionTree_VS_RandomForest/blob/main/DT_Test.png" alt="DT_Test">
</br>
Decision Tree in Train Dataset
<img src="https://github.com/yazdanzv/DecisionTree_VS_RandomForest/blob/main/DT_Train.png" alt="DT_Train">
</br>
Decision Tree Results
<img src="https://github.com/yazdanzv/DecisionTree_VS_RandomForest/blob/main/DT.png" alt="DT">
</br>
</br>
Random Forest on Test Dataset
<img src="https://github.com/yazdanzv/DecisionTree_VS_RandomForest/blob/main/RF_Test.png" alt="RF_Test">
</br>
Random Forest on Train Dataset
<img src="https://github.com/yazdanzv/DecisionTree_VS_RandomForest/blob/main/RF_Train.png" alt="RF_Train">
</br>
Random Forest Results 
<img src="https://github.com/yazdanzv/DecisionTree_VS_RandomForest/blob/main/RF.png" alt="RF">
<h3>NOTE</h3>
This program is done with GridSearchCV in sklearn library and used metrics classes in sklearn and also used RandomForestClassifier and DecisionTreeClassifier in it too
Good of GridSearchCV is that it returns the best estimator and the best parameters but if you use cross_validate in sklearn it is better in results bbut it does not return the best parameters and estimator, however the algorithm in both of them are kfold cross validation
</br>
</br>
<h4>you can see the result of the decision tree that I coded with cross_validate function in sklearn down here</h4>
</br>
Results on Train & Validation dataset
<img src="https://github.com/yazdanzv/DecisionTree_VS_RandomForest/blob/main/sth1.png" alt="sth1">
</br>
Results on test Dataset
<img src="https://github.com/yazdanzv/DecisionTree_VS_RandomForest/blob/main/sth2.png" alt="sth2">
